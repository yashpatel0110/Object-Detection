# Step 1: Install required packages
!pip install opencv-python
!pip install opencv-python-headless

# Step 2: Download YOLOv3 weights and config files
# Download the YOLOv3 weights
!wget https://pjreddie.com/media/files/yolov3.weights

# Download the YOLOv3 config file
!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg

# Download the COCO names file
!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names

# Step 3: Import necessary libraries
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Step 4: Load YOLO network
net = cv2.dnn.readNet("yolov3.weights", "yolov3.cfg")

# Get the layer names of the network
layer_names = net.getLayerNames()

# Fix: Use .flatten() to handle scalar output issue with newer OpenCV versions
unconnected_out_layers = net.getUnconnectedOutLayers()
output_layers = [layer_names[i - 1] for i in unconnected_out_layers.flatten()]

# Load the COCO class labels
with open("coco.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]


# Step 5: Upload an image
from google.colab import files
uploaded = files.upload()

# Assuming the uploaded image is named 'input_image.jpg'
input_image_name = list(uploaded.keys())[0]

# Load the image
img = cv2.imread(input_image_name)
height, width, channels = img.shape

# Step 6: Preprocess the image for YOLO
blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
net.setInput(blob)
outs = net.forward(output_layers)

# Initialize lists for detected bounding boxes, confidences, and class IDs
boxes = []
confidences = []
class_ids = []

# Step 7: Iterate over the detections and filter based on confidence
for out in outs:
    for detection in out:
        scores = detection[5:]
        class_id = np.argmax(scores)
        confidence = scores[class_id]
        if confidence > 0.5:  # Confidence threshold
            center_x = int(detection[0] * width)
            center_y = int(detection[1] * height)
            w = int(detection[2] * width)
            h = int(detection[3] * height)
            x = int(center_x - w / 2)
            y = int(center_y - h / 2)
            boxes.append([x, y, w, h])
            confidences.append(float(confidence))
            class_ids.append(class_id)

# Perform non-max suppression to eliminate redundant overlapping boxes
indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

# Step 8: Draw bounding boxes and labels on the image
if np.isscalar(indices):
    indices = [indices]



for i in indices:
    box = boxes[i]
    x, y, w, h = box[0], box[1], box[2], box[3]
    label = str(classes[class_ids[i]])
    confidence = confidences[i]
    color = (0, 255, 0)  # Green for bounding boxes
    cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)
    cv2.putText(img, f"{label} {confidence:.2f}", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 2, color, 10)



# Step 9: Convert image to RGB for displaying in Colab
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)



# Display image using matplotlib with dynamically calculated figsize
plt.figure(figsize=(10, 10))
plt.imshow(img_rgb)
plt.axis('off')  # Hide axis for better visualization
plt.show()
